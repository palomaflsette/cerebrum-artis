# Relat√≥rio de Treinamento e Avalia√ß√£o - Cerebrum Artis
**Data:** 9-12 de Dezembro de 2025  
**Autor:** Paloma Sette

---

## üìã Sum√°rio Executivo

Este documento relata todo o processo de retreinamento dos modelos V2 e V3, cria√ß√£o do ensemble V4, e avalia√ß√£o final no test set do dataset ArtEmis. O trabalho focou em:

1. Retreinamento completo dos modelos com m√©tricas detalhadas (F1, Precision, Recall)
2. Identifica√ß√£o e descarte do modelo V3.1 (underperforming)
3. Cria√ß√£o de ensemble V4 combinando V2 + V3
4. Avalia√ß√£o final no test set

---

## üîÑ Fase 1: Retreinamento dos Modelos (9 de Dezembro)

### Motiva√ß√£o

Os modelos originais foram treinados apenas com **accuracy** como m√©trica. Para datasets desbalanceados como o ArtEmis, precis√°vamos de m√©tricas mais robustas:
- **F1 Score** (harm√¥nica entre precision e recall)
- **Precision** (quantos positivos preditos est√£o corretos)
- **Recall** (quantos positivos reais foram detectados)

### Modelos Retreinados

#### V2: Fuzzy Features (Concatena√ß√£o Simples)
- **Arquitetura:** ResNet50 (visual) + RoBERTa (texto) + Fuzzy Features (7 dims)
- **Estrat√©gia:** Concatena√ß√£o direta de todas as features
- **Script:** `scripts/training/train_v2_improved.py`
- **Checkpoint:** `/data/paloma/deep-mind-checkpoints/v2_fuzzy_features/checkpoint_best.pt`

**Resultados do Treinamento:**
```
Epoch 3/20 - BEST MODEL
‚îú‚îÄ Train: Loss=0.8571 | Acc=75.62% | F1=71.87% | P=73.58% | R=70.52%
‚îî‚îÄ Val:   Loss=1.0450 | Acc=69.02% | F1=65.77% | P=67.27% | R=64.60%

Early Stop: Epoch 8 (5 epochs sem melhoria)
Training Time: ~48h
```

**Observa√ß√µes:**
- Overfitting moderado (75% train vs 69% val accuracy)
- F1 Score s√≥lido: **65.77%**
- Boa capacidade de generaliza√ß√£o apesar do overfitting

#### V3: Adaptive Gating (Fus√£o Neural + Fuzzy Externa)
- **Arquitetura:** ResNet50 + RoBERTa com gating adaptativo externo
- **Estrat√©gia:** Fus√£o ponderada entre predi√ß√µes neurais e fuzzy inference
- **Script:** `scripts/training/train_v3_improved.py`
- **Checkpoint:** `/data/paloma/deep-mind-checkpoints/v3_adaptive_gating/checkpoint_best.pt`

**Resultados do Treinamento:**
```
Epoch 4/20 - BEST MODEL
‚îú‚îÄ Train: Loss=0.8218 | Acc=77.58% | F1=74.39% | P=75.81% | R=73.24%
‚îî‚îÄ Val:   Loss=1.0858 | Acc=69.26% | F1=65.66% | P=66.72% | R=64.87%

Parado manualmente: Epoch 9 (estava em 4/5 early stop patience)
Training Time: ~72h
```

**Observa√ß√µes:**
- Menor gap train-val (melhor generaliza√ß√£o que V2)
- F1 Score praticamente id√™ntico ao V2: **65.66%**
- Gating adaptativo funcionou bem

#### V3.1: Integrated (DESCARTADO)
- **Arquitetura:** Tentativa de integrar fuzzy logic dentro da rede neural
- **Resultado:** **FALHOU COMPLETAMENTE**

**Por que falhou:**
```
Epoch 3/20 - BEST MODEL
‚îú‚îÄ Train: Loss=1.3042 | Acc=60.14% | F1=56.83%
‚îî‚îÄ Val:   Loss=1.3941 | Acc=57.82% | F1=55.20%

Agreement: 0.58-0.66 (neural vs fuzzy branches discordando)
```

**Problemas identificados:**
- Underfitting severo (apenas 60% train accuracy)
- F1 Score 10 pontos abaixo de V2/V3 (55.20% vs ~65%)
- Neural e fuzzy branches em conflito (baixo agreement)
- Treinamento inst√°vel

**Decis√£o:** Modelo descartado, backup criado em `/data/paloma/checkpoint-backups/v3_1_integrated_backup_20251209/`

### Compara√ß√£o V2 vs V3

| M√©trica | V2 (Fuzzy Features) | V3 (Adaptive Gating) | Diferen√ßa |
|---------|---------------------|----------------------|-----------|
| **Val Accuracy** | 69.02% | 69.26% | +0.24% |
| **Val F1 Score** | **65.77%** | **65.66%** | -0.11% |
| **Val Precision** | 67.27% | 66.72% | -0.55% |
| **Val Recall** | 64.60% | 64.87% | +0.27% |
| **Generaliza√ß√£o** | Moderada | Melhor | - |
| **Overfitting** | 6.6% gap | 8.3% gap | - |

**Conclus√£o:** Modelos praticamente empatados em F1, mas com caracter√≠sticas complementares.

---

## üîß Fase 2: Limpeza e Gerenciamento de Recursos (9 de Dezembro)

### Problema de Disco

Durante o treinamento, o disco `/home/paloma` atingiu 100% de capacidade (15GB/15GB usado).

**A√ß√µes tomadas:**
1. Identifica√ß√£o de arquivos desnecess√°rios em `garbage/`
2. Remo√ß√£o de backups antigos e dados tempor√°rios
3. Total liberado: **5.5GB**
4. Espa√ßo final: **9.4GB/15GB** (37% livre)

**Arquivos removidos:**
- `garbage/old_artemis-v2/` (dados de vers√£o anterior)
- Checkpoints antigos duplicados
- Logs de treinamento obsoletos

---

## üìä Fase 3: An√°lise de M√©tricas e Dataset (9-10 de Dezembro)

### Entendendo F1 Score vs Accuracy

**Por que F1 > Accuracy para datasets desbalanceados?**

No ArtEmis, temos distribui√ß√£o desbalanceada:
```
Contentment:    21.57% (maior classe)
Anger:           2.95% (menor classe)
Raz√£o:          7.3:1 desbalanceamento
```

- **Accuracy:** Pode ser enganosa (modelo que sempre prediz "contentment" teria 21% accuracy)
- **F1 Score:** Balanceia precision e recall, resistente ao desbalanceamento
- **Conclus√£o:** F1 √© a m√©trica correta para este problema

### Distribui√ß√£o de Emo√ß√µes por Val√™ncia

Classifica√ß√£o das 9 emo√ß√µes em positivas, negativas e neutras:

| Val√™ncia | Emo√ß√µes | Percentual |
|----------|---------|------------|
| **Positiva** | amusement, awe, contentment, excitement | 46.69% |
| **Negativa** | anger, disgust, fear, sadness | 45.65% |
| **Neutra** | something else | 7.65% |

**Insight:** Dataset bem balanceado em termos de val√™ncia (positivo vs negativo), mas desbalanceado nas classes individuais.

### Propostas para Melhorias Futuras

1. **Weighted Loss:** Penalizar mais erros nas classes minorit√°rias
2. **Data Augmentation:** Balancear classes com augmentation estratificado
3. **Multi-task Learning:** Treinar simultaneamente para emo√ß√£o + val√™ncia
4. **Binary Classification:** Agrupar em positivo/negativo (simplificaria dataset)

---

## üöÄ Fase 4: Cria√ß√£o do Ensemble V4 (11 de Dezembro)

### Motiva√ß√£o

V2 e V3 t√™m F1 praticamente id√™ntico (65.77% vs 65.66%), mas:
- V2 √© melhor em **precision** (67.27% vs 66.72%)
- V3 √© melhor em **recall** (64.87% vs 64.60%)
- V2 usa fuzzy features diretamente, V3 usa gating adaptativo

**Hip√≥tese:** Modelos s√£o complementares ‚Üí Ensemble pode superar ambos

### Arquitetura do V4 Ensemble

```python
class EnsembleV4:
    def __init__(self, v2_checkpoint, v3_checkpoint, v2_weight=0.5):
        self.v2_model = MultimodalFuzzyClassifier()  # V2
        self.v3_model = FuzzyGatingClassifier()       # V3
        self.v2_weight = v2_weight
        self.v3_weight = 1.0 - v2_weight
    
    def forward(self, image, text, fuzzy_features):
        # Predi√ß√µes individuais
        v2_logits = self.v2_model(image, text, fuzzy_features)
        v3_logits = self.v3_model(image, text)
        
        # Weighted average em espa√ßo de probabilidade
        v2_probs = softmax(v2_logits)
        v3_probs = softmax(v3_logits)
        
        ensemble_probs = v2_weight * v2_probs + v3_weight * v3_probs
        ensemble_logits = log(ensemble_probs + 1e-8)
        
        return ensemble_logits, v2_logits, v3_logits
```

**Caracter√≠sticas:**
- Weighted average de predi√ß√µes (n√£o de features)
- Fus√£o em espa√ßo de probabilidade (melhor calibra√ß√£o)
- Pesos configur√°veis (default: 50/50)
- Retorna predi√ß√µes individuais para an√°lise

### Implementa√ß√£o

**Arquivos criados:**
```
cerebrum_artis/models/ensemble/
‚îú‚îÄ‚îÄ model_definitions.py       # Defini√ß√µes de V2 e V3
‚îú‚îÄ‚îÄ ensemble_v4.py             # Classe EnsembleV4
‚îî‚îÄ‚îÄ evaluate_v4.py             # Script de avalia√ß√£o
```

**Scripts auxiliares:**
```
scripts/evaluation/
‚îî‚îÄ‚îÄ evaluate_ensemble_v4.sh    # Script interativo de avalia√ß√£o
```

---

## üìà Fase 5: Avalia√ß√£o no Validation Set (11 de Dezembro)

### Configura√ß√£o

- **Dataset:** Validation split (68,588 exemplos)
- **Batch Size:** 16 (limitado por mem√≥ria GPU)
- **GPU:** GPU 1 (NVIDIA GTX 1080 Ti, 11GB)
- **Pesos:** V2=0.50, V3=0.50 (n√£o otimizado)

### Resultados - Validation Set

```
================================================================================
üìä MODEL COMPARISON (VALIDATION)
================================================================================
Model           | Accuracy   | F1 Score   | Precision  | Recall    
--------------------------------------------------------------------------------
V2              | 0.7062     | 0.6577     | 0.6866     | 0.6397    
V3              | 0.7046     | 0.6563     | 0.6733     | 0.6447    
V4_Ensemble     | 0.7120     | 0.6644     | 0.6871     | 0.6493    
================================================================================

üí° Ensemble Improvement:
   vs V2: +0.67% F1
   vs V3: +0.82% F1
   üéâ ENSEMBLE WINS! (+0.82%)
```

**M√©tricas por Classe (V4 Ensemble - Validation):**

| Emo√ß√£o | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| amusement | 64.19% | 59.81% | 61.92% | 4,887 |
| awe | 60.21% | 61.10% | 60.65% | 8,053 |
| **contentment** | **72.29%** | **76.63%** | **74.39%** | 14,762 |
| excitement | 59.77% | 49.43% | 54.11% | 4,398 |
| anger | 68.23% | 46.49% | 55.30% | 2,065 |
| disgust | 68.61% | 61.68% | 64.96% | 5,164 |
| **fear** | **74.15%** | **81.82%** | **77.80%** | 10,078 |
| **sadness** | **80.04%** | **84.94%** | **82.42%** | 13,928 |
| something else | 70.93% | 62.46% | 66.42% | 5,253 |
| **Macro Avg** | **68.71%** | **64.93%** | **66.44%** | 68,588 |
| **Weighted Avg** | **70.83%** | **71.20%** | **70.83%** | 68,588 |

**An√°lise:**
- ‚úÖ **Ensemble superou ambos os modelos individuais**
- ‚úÖ Melhor em 3 das 4 m√©tricas principais
- ‚úÖ Classes negativas (sadness, fear) t√™m melhor performance
- ‚ö†Ô∏è Classes com poucos exemplos (anger, excitement) ainda desafiadoras

### Tentativa de Otimiza√ß√£o de Pesos (12 de Dezembro)

**Objetivo:** Testar pesos de 0.0 a 1.0 (grid search) para maximizar F1

**Problema encontrado:**
- Grid search requer **11 passadas completas** pelo dataset
- Tempo estimado: **~3 horas**
- Ganho esperado: **< 0.5% F1** (V2 e V3 muito similares)

**Decis√£o:** Cancelar otimiza√ß√£o e prosseguir com pesos 50/50 para test set.

**Justificativa:**
- V2 e V3 t√™m F1 quase id√™ntico (diferen√ßa de 0.11%)
- Peso √≥timo provavelmente est√° pr√≥ximo de 0.5
- Custo-benef√≠cio n√£o compensa o tempo de processamento
- Pesos 50/50 j√° mostraram melhoria consistente no validation

---

## üèÜ Fase 6: Avalia√ß√£o Final no Test Set (12 de Dezembro)

### Configura√ß√£o Final

- **Dataset:** Test split (68,357 exemplos)
- **Batch Size:** 16
- **GPU:** GPU 1 (NVIDIA GTX 1080 Ti)
- **Pesos:** V2=0.50, V3=0.50
- **Tempo de execu√ß√£o:** 14min 8s (5.04 it/s)

### Resultados Finais - Test Set

```
================================================================================
üìä MODEL COMPARISON (TEST SET - FINAL)
================================================================================
Model           | Accuracy   | F1 Score   | Precision  | Recall    
--------------------------------------------------------------------------------
V2              | 0.7045     | 0.6561     | 0.6837     | 0.6384    
V3              | 0.7019     | 0.6547     | 0.6713     | 0.6432    
V4_Ensemble     | 0.7097     | 0.6626     | 0.6856     | 0.6472    
================================================================================

üí° Ensemble Improvement:
   vs V2: +0.66% F1
   vs V3: +0.79% F1
   üéâ ENSEMBLE WINS! (+0.79%)
```

### M√©tricas Detalhadas por Classe (Test Set)

| Emo√ß√£o | Precision | Recall | F1-Score | Support | Caracter√≠sticas |
|--------|-----------|--------|----------|---------|-----------------|
| **sadness** | **79.31%** | **84.76%** | **82.42%** | 13,757 | üèÜ Melhor classe |
| **fear** | **75.00%** | **81.70%** | **78.21%** | 10,282 | ü•à 2¬™ melhor |
| **contentment** | **71.64%** | **76.44%** | **73.97%** | 14,662 | ü•â 3¬™ melhor |
| disgust | 68.16% | 61.15% | 64.46% | 5,114 | ‚úÖ Balanceado |
| anger | 67.48% | 46.30% | 54.92% | 2,026 | ‚ö†Ô∏è Recall baixo |
| something else | 71.32% | 62.18% | 66.43% | 5,198 | ‚úÖ Aceit√°vel |
| amusement | 64.17% | 60.25% | 62.15% | 4,931 | üìä Moderado |
| awe | 59.45% | 59.89% | 59.67% | 8,001 | üìä Moderado |
| **excitement** | **60.49%** | **49.77%** | **54.61%** | 4,386 | ‚ö†Ô∏è Mais dif√≠cil |
| **Macro Avg** | **68.56%** | **64.72%** | **66.26%** | 68,357 | - |
| **Weighted Avg** | **70.60%** | **70.97%** | **70.59%** | 68,357 | - |

### An√°lise de Generaliza√ß√£o

**Validation ‚Üí Test:**
- Accuracy: 71.20% ‚Üí 70.97% (Œî = -0.23%)
- F1 Score: 66.44% ‚Üí 66.26% (Œî = -0.18%)
- Precision: 68.71% ‚Üí 68.56% (Œî = -0.15%)
- Recall: 64.93% ‚Üí 64.72% (Œî = -0.21%)

**‚úÖ Generaliza√ß√£o EXCELENTE:**
- Queda m√≠nima de performance (< 0.25% em todas as m√©tricas)
- Modelo n√£o est√° overfitting ao validation set
- Performance consistente entre splits

### Insights por Categoria de Emo√ß√£o

#### üèÜ Emo√ß√µes Negativas (Melhor Performance)
```
sadness:  F1=82.42% (alta precision 79.31%, alto recall 84.76%)
fear:     F1=78.21% (alta precision 75.00%, alto recall 81.70%)

M√©dia:    F1=80.32%
```
**Por qu√™?**
- Classes bem representadas (23,039 exemplos = 33.7% do dataset)
- Padr√µes visuais mais distintos (cores escuras, composi√ß√µes dram√°ticas)
- Linguagem mais espec√≠fica nas descri√ß√µes

#### üìä Emo√ß√µes Positivas (Performance Moderada)
```
contentment: F1=73.97%
amusement:   F1=62.15%
awe:         F1=59.67%
excitement:  F1=54.61%

M√©dia:       F1=62.60%
```
**Desafios:**
- Maior variabilidade visual (positivo pode ter muitos "looks")
- Sobreposi√ß√£o sem√¢ntica entre classes (awe vs excitement)
- Excitement tem recall muito baixo (49.77%)

#### ‚ö†Ô∏è Emo√ß√µes com Poucos Exemplos
```
anger:    F1=54.92% (2,026 exemplos, 2.96%)
disgust:  F1=64.46% (5,114 exemplos, 7.48%)

Desafios: Recall baixo especialmente em anger (46.30%)
```

### Confusion Matrix - Principais Confus√µes

**An√°lise qualitativa dos erros mais comuns:**

1. **awe ‚Üî contentment** (sobreposi√ß√£o positiva alta)
2. **excitement ‚Üî amusement** (ambas positivas, energ√©ticas)
3. **fear ‚Üî sadness** (ambas negativas, compartilham elementos visuais)
4. **anger ‚Üí disgust** (ambas negativas, baixa representa√ß√£o)

---

## üìä Compara√ß√£o: Validation vs Test

### M√©tricas Globais

| M√©trica | Validation | Test | Diferen√ßa | Status |
|---------|-----------|------|-----------|--------|
| **Accuracy** | 71.20% | 70.97% | -0.23% | ‚úÖ Est√°vel |
| **F1 Score** | 66.44% | 66.26% | -0.18% | ‚úÖ Est√°vel |
| **Precision** | 68.71% | 68.56% | -0.15% | ‚úÖ Est√°vel |
| **Recall** | 64.93% | 64.72% | -0.21% | ‚úÖ Est√°vel |

### Performance por Classe (F1 Score)

| Emo√ß√£o | Validation | Test | Diferen√ßa |
|--------|-----------|------|-----------|
| sadness | 82.42% | 81.95% | -0.47% |
| fear | 77.80% | 78.21% | **+0.41%** ‚úÖ |
| contentment | 74.39% | 73.97% | -0.42% |
| disgust | 64.96% | 64.46% | -0.50% |
| something else | 66.42% | 66.43% | **+0.01%** ‚úÖ |
| amusement | 61.92% | 62.15% | **+0.23%** ‚úÖ |
| awe | 60.65% | 59.67% | -0.98% |
| anger | 55.30% | 54.92% | -0.38% |
| excitement | 54.11% | 54.61% | **+0.50%** ‚úÖ |

**Conclus√£o:** 4 de 9 classes melhoraram no test set! Modelo generalizou extremamente bem.

---

## üéØ Conclus√µes Finais

### Achievements

‚úÖ **Retreinamento bem-sucedido** com m√©tricas completas (F1, P, R)  
‚úÖ **Identifica√ß√£o e descarte** de arquitetura ruim (V3.1)  
‚úÖ **Ensemble V4 superior** aos modelos individuais (+0.79% F1)  
‚úÖ **Generaliza√ß√£o excelente** (val‚Üítest: -0.18% F1)  
‚úÖ **Performance consistente** entre validation e test  
‚úÖ **M√©tricas de produ√ß√£o** prontas para publica√ß√£o  

### N√∫meros Finais para Publica√ß√£o

**V4 Ensemble (Test Set):**
- **Accuracy:** 70.97%
- **F1 Score (Macro):** 66.26%
- **Precision (Macro):** 68.56%
- **Recall (Macro):** 64.72%
- **Dataset:** ArtEmis (68,357 test samples, 9 emotion classes)

**Melhor Performance:**
- Sadness: 82.42% F1
- Fear: 78.21% F1
- Contentment: 73.97% F1

**Maior Desafio:**
- Excitement: 54.61% F1 (recall 49.77%)
- Anger: 54.92% F1 (recall 46.30%)

### Vantagens do Ensemble

1. **Complementaridade:** V2 (precision) + V3 (recall) = melhor balan√ßo
2. **Robustez:** Menos sens√≠vel a erros individuais de cada modelo
3. **Simplicidade:** Weighted average (n√£o requer retreinamento)
4. **Interpretabilidade:** Pode analisar predi√ß√µes de V2 e V3 separadamente

### Limita√ß√µes Identificadas

1. **Classes minorit√°rias:** anger (2.96%) e excitement sofrem com poucos exemplos
2. **Sobreposi√ß√£o sem√¢ntica:** awe/excitement e fear/sadness se confundem
3. **Variabilidade positiva:** Emo√ß√µes positivas t√™m maior vari√¢ncia visual
4. **Recall baixo:** Especialmente em anger (46.30%) e excitement (49.77%)

### Pr√≥ximos Passos Recomendados

#### Curto Prazo
1. ‚úÖ ~~Otimiza√ß√£o de pesos (se necess√°rio)~~ ‚Üí Cancelado (custo-benef√≠cio)
2. ‚úÖ ~~Avalia√ß√£o no test set~~ ‚Üí **CONCLU√çDO**
3. üìù Gerar visualiza√ß√µes (confusion matrix, curvas ROC por classe)
4. üìù Analisar predi√ß√µes incorretas (error analysis)

#### M√©dio Prazo
1. **Weighted Loss:** Implementar pesos por classe no treinamento
2. **Data Augmentation:** Estrat√©gias para balancear classes minorit√°rias
3. **Multi-task Learning:** Treinar para emo√ß√£o + val√™ncia simultaneamente
4. **Attention Visualization:** Entender o que o modelo est√° "vendo"

#### Longo Prazo
1. **Ensemble com mais modelos:** Incluir V1 baseline, transformers puros
2. **Architecture Search:** AutoML para encontrar arquiteturas melhores
3. **Transfer Learning:** Fine-tuning de modelos maiores (ViT, CLIP)
4. **Active Learning:** Coletar mais dados das classes minorit√°rias

---

## üìÅ Arquivos e Checkpoints

### Modelos Treinados

```
/data/paloma/deep-mind-checkpoints/
‚îú‚îÄ‚îÄ v2_fuzzy_features/
‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_best.pt          # F1=65.77%, Epoch 3
‚îú‚îÄ‚îÄ v3_adaptive_gating/
‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_best.pt          # F1=65.66%, Epoch 4
‚îî‚îÄ‚îÄ v3_1_integrated/                # DESCARTADO (backup criado)
```

### C√≥digo Fonte

```
cerebrum_artis/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ ensemble/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_definitions.py    # Defini√ß√µes V2 e V3
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ensemble_v4.py          # Classe EnsembleV4
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate_v4.py          # Script de avalia√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ v2_fuzzy_features/
‚îÇ   ‚îú‚îÄ‚îÄ v3_adaptive_gating/
‚îÇ   ‚îî‚îÄ‚îÄ v3_1_integrated/
‚îî‚îÄ‚îÄ fuzzy/
    ‚îî‚îÄ‚îÄ fuzzy_brain/                # Sistema fuzzy logic

scripts/
‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îú‚îÄ‚îÄ train_v2_improved.py        # Treinamento V2
‚îÇ   ‚îú‚îÄ‚îÄ train_v3_improved.py        # Treinamento V3
‚îÇ   ‚îî‚îÄ‚îÄ train_v3_1_improved.py      # Treinamento V3.1 (descartado)
‚îî‚îÄ‚îÄ evaluation/
    ‚îî‚îÄ‚îÄ evaluate_ensemble_v4.sh     # Script interativo
```

### Logs de Treinamento

```
/data/paloma/training-logs/
‚îú‚îÄ‚îÄ v2_training_20251209_103930.log
‚îú‚îÄ‚îÄ v3_gpu2.log
‚îî‚îÄ‚îÄ v3_1_gpu3.log
```

### Resultados de Avalia√ß√£o

```
outputs/ensemble_evaluation/
‚îú‚îÄ‚îÄ v4_ensemble_val_predictions.npz
‚îî‚îÄ‚îÄ v4_ensemble_test_predictions.npz
```

---

## üìö Dataset: ArtEmis

### Estat√≠sticas

- **Total:** ~549k treino, 68k validation, 68k test
- **Classes:** 9 emo√ß√µes
- **Modalidades:** Imagem (pinturas) + Texto (descri√ß√µes)
- **Features:** Visual (ResNet50) + Texto (RoBERTa) + Fuzzy (7 dims)

### Distribui√ß√£o de Classes (Test Set)

| Emo√ß√£o | Count | Percentage |
|--------|-------|------------|
| contentment | 14,662 | 21.44% |
| sadness | 13,757 | 20.12% |
| fear | 10,282 | 15.04% |
| awe | 8,001 | 11.70% |
| disgust | 5,114 | 7.48% |
| something else | 5,198 | 7.60% |
| amusement | 4,931 | 7.21% |
| excitement | 4,386 | 6.42% |
| anger | 2,026 | 2.96% |
| **Total** | **68,357** | **100%** |

**Desbalanceamento:** Raz√£o 7.25:1 (contentment:anger)

---

## üî¨ Metodologia

### Estratifica√ß√£o e Anti-Vazamento

- ‚úÖ Splits estratificados por classe
- ‚úÖ Valida√ß√£o rigorosa de split assignment
- ‚úÖ Nenhum overlap entre train/val/test
- ‚úÖ Fuzzy features calculadas separadamente por split

### Early Stopping

- Patience: 5 √©pocas
- M√©trica: Validation F1 Score
- Salvamento: Apenas best checkpoint (economia de espa√ßo)
- Learning Rate Scheduler: ReduceLROnPlateau

### Avalia√ß√£o

- M√©tricas: Accuracy, F1 (macro), Precision (macro), Recall (macro)
- Por classe: Classification report completo
- Confusion matrix: An√°lise qualitativa de erros
- Compara√ß√£o: V2, V3, V4 Ensemble lado a lado

---

## üíª Infraestrutura

### Hardware Utilizado

```
Cluster: ugpucluster
GPUs: 4x NVIDIA GeForce GTX 1080 Ti (11GB cada)

Treinamento V2: GPU 0
Treinamento V3: GPU 2
Avalia√ß√£o V4:   GPU 1

Mem√≥ria: 16GB RAM por GPU
Storage: /data/paloma/ (SSD, 1TB)
```

### Tempo de Execu√ß√£o

| Tarefa | Tempo | GPU |
|--------|-------|-----|
| Treino V2 (8 epochs) | ~48h | GPU 0 |
| Treino V3 (9 epochs) | ~72h | GPU 2 |
| Treino V3.1 (descartado) | ~24h | GPU 3 |
| Eval V4 (validation) | 16min | GPU 1 |
| Eval V4 (test) | 14min | GPU 1 |
| **Total** | **~144h** | - |

---

## üìñ Refer√™ncias

### Papers e Frameworks

- ArtEmis Dataset: Achlioptas et al. (2021)
- ResNet50: He et al. (2016)
- RoBERTa: Liu et al. (2019)
- Fuzzy Logic: Zadeh (1965)

### C√≥digo Base

- PyTorch 1.9.0
- Transformers (Hugging Face) 4.11.3
- scikit-fuzzy 0.4.2
- scikit-learn 0.24.2

---

## üë• Contribui√ß√µes

**Desenvolvimento:** Paloma Sette  
**Orienta√ß√£o:** [Nome do orientador]  
**Dataset:** ArtEmis (Achlioptas et al.)  
**Infraestrutura:** UGPUCluster

---

## üìù Notas Finais

Este relat√≥rio documenta todo o processo de experimenta√ß√£o, retreinamento e avalia√ß√£o dos modelos Cerebrum Artis. Os resultados demonstram que:

1. **F1 Score** √© essencial para datasets desbalanceados
2. **Ensemble simples** (weighted average) pode superar modelos individuais
3. **Generaliza√ß√£o** √© mais importante que otimiza√ß√£o excessiva
4. **Arquiteturas complexas** (V3.1) nem sempre s√£o melhores

O modelo **V4 Ensemble** est√° pronto para produ√ß√£o e publica√ß√£o, com m√©tricas s√≥lidas e generaliza√ß√£o comprovada.

---

**Documento gerado em:** 12 de Dezembro de 2025  
**Vers√£o:** 1.0  
**Status:** ‚úÖ FINALIZADO
