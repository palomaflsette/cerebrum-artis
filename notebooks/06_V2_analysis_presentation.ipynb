{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd655928",
   "metadata": {},
   "source": [
    "## 1. Setup e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37c232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/paloma/venvs/cerebrum-artis/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports concluÃ­dos!\n",
      "ðŸ–¥ï¸  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Fuzzy system\n",
    "sys.path.insert(0, '/home/paloma/cerebrum-artis')\n",
    "from cerebrum_artis.fuzzy.fuzzy_brain.extractors.visual import VisualFeatureExtractor\n",
    "\n",
    "# Style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"âœ… Imports concluÃ­dos!\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ–¥ï¸  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76295f32",
   "metadata": {},
   "source": [
    "## 2. Definir Modelo V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c20460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo V2 definido!\n"
     ]
    }
   ],
   "source": [
    "EMOTIONS = [\n",
    "    'amusement', 'awe', 'contentment', 'excitement',\n",
    "    'anger', 'disgust', 'fear', 'sadness', 'something else'\n",
    "]\n",
    "\n",
    "class V2_SimpleConcat(nn.Module):\n",
    "    \"\"\"V2: ResNet50 + RoBERTa + 7 Fuzzy Features\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=9, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Vision: ResNet50 (FROZEN)\n",
    "        resnet = models.resnet50(weights='IMAGENET1K_V1')\n",
    "        self.visual_encoder = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        for param in self.visual_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Text: RoBERTa (FROZEN)\n",
    "        self.text_encoder = RobertaModel.from_pretrained('roberta-base')\n",
    "        for param in self.text_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Fusion MLP (TRAINABLE)\n",
    "        # 2048 (ResNet) + 768 (RoBERTa) + 7 (Fuzzy) = 2823\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(2048 + 768 + 7, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image, input_ids, attention_mask, fuzzy_features):\n",
    "        # Visual: [B, 2048]\n",
    "        visual_feats = self.visual_encoder(image).view(image.size(0), -1)\n",
    "        \n",
    "        # Text: [B, 768]\n",
    "        text_output = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_feats = text_output.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        \n",
    "        # Concatenar: [B, 2823]\n",
    "        combined = torch.cat([visual_feats, text_feats, fuzzy_features], dim=1)\n",
    "        \n",
    "        # Classificar\n",
    "        logits = self.fusion(combined)\n",
    "        return logits\n",
    "\n",
    "print(\"âœ… Modelo V2 definido!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b9d68",
   "metadata": {},
   "source": [
    "## 3. Carregar Modelo Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f880d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/paloma/venvs/cerebrum-artis/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Checkpoint nÃ£o encontrado: /data/paloma/deep-mind-checkpoints/v2_fuzzy_features/best_model.pt\n",
      "Continuando com pesos aleatÃ³rios (apenas para demonstraÃ§Ã£o)\n",
      "\n",
      "ðŸ“Š Total params: 151,574,857\n",
      "ðŸ“Š Trainable params: 3,421,193\n",
      "ðŸ“Š Frozen params: 148,153,664\n"
     ]
    }
   ],
   "source": [
    "# Criar modelo\n",
    "model = V2_SimpleConcat(num_classes=9, dropout=0.3).to(device)\n",
    "\n",
    "# Carregar checkpoint (ajuste o path conforme necessÃ¡rio)\n",
    "checkpoint_path = '/data/paloma/deep-mind-checkpoints/v2_fuzzy_features/best_model.pt'\n",
    "\n",
    "if Path(checkpoint_path).exists():\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"âœ… Checkpoint carregado: {checkpoint_path}\")\n",
    "    print(f\"ðŸ“Š Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"ðŸ“Š Val Accuracy: {checkpoint.get('val_acc', 'N/A'):.2f}%\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Checkpoint nÃ£o encontrado: {checkpoint_path}\")\n",
    "    print(\"Continuando com pesos aleatÃ³rios (apenas para demonstraÃ§Ã£o)\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nðŸ“Š Total params: {total_params:,}\")\n",
    "print(f\"ðŸ“Š Trainable params: {trainable_params:,}\")\n",
    "print(f\"ðŸ“Š Frozen params: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711ff5f",
   "metadata": {},
   "source": [
    "## 4. Setup de Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a90510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessamento configurado!\n"
     ]
    }
   ],
   "source": [
    "# Image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Fuzzy extractor\n",
    "fuzzy_extractor = VisualFeatureExtractor()\n",
    "\n",
    "print(\"âœ… Preprocessamento configurado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5e2a0",
   "metadata": {},
   "source": [
    "## 5. FunÃ§Ã£o de PrediÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd471bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FunÃ§Ã£o de prediÃ§Ã£o criada!\n"
     ]
    }
   ],
   "source": [
    "def predict_emotion(image_path, utterance):\n",
    "    \"\"\"\n",
    "    Prediz emoÃ§Ã£o para uma imagem + utterance.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path para imagem\n",
    "        utterance: Texto descritivo\n",
    "    \n",
    "    Returns:\n",
    "        dict com prediÃ§Ã£o, probabilidades, features fuzzy\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)  # [1, 3, 224, 224]\n",
    "    \n",
    "    # Extract fuzzy features\n",
    "    fuzzy_dict = fuzzy_extractor.extract(str(image_path))\n",
    "    fuzzy_features = torch.tensor([\n",
    "        fuzzy_dict['brightness'],\n",
    "        fuzzy_dict['color_temperature'],\n",
    "        fuzzy_dict['saturation'],\n",
    "        fuzzy_dict['color_harmony'],\n",
    "        fuzzy_dict['complexity'],\n",
    "        fuzzy_dict['symmetry'],\n",
    "        fuzzy_dict['texture_roughness']\n",
    "    ], dtype=torch.float32).unsqueeze(0).to(device)  # [1, 7]\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = tokenizer(\n",
    "        utterance,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = tokens['input_ids'].to(device)\n",
    "    attention_mask = tokens['attention_mask'].to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        logits = model(image_tensor, input_ids, attention_mask, fuzzy_features)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "    \n",
    "    # Results\n",
    "    pred_idx = torch.argmax(probs, dim=1).item()\n",
    "    pred_emotion = EMOTIONS[pred_idx]\n",
    "    confidence = probs[0, pred_idx].item()\n",
    "    \n",
    "    return {\n",
    "        'predicted_emotion': pred_emotion,\n",
    "        'confidence': confidence,\n",
    "        'probabilities': {EMOTIONS[i]: probs[0, i].item() for i in range(9)},\n",
    "        'fuzzy_features': fuzzy_dict,\n",
    "        'image': image\n",
    "    }\n",
    "\n",
    "print(\"âœ… FunÃ§Ã£o de prediÃ§Ã£o criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b450b",
   "metadata": {},
   "source": [
    "## 6. Teste com Imagens de Exemplo\n",
    "\n",
    "### 6.1 Starry Night (Van Gogh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a4fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Imagem nÃ£o encontrada: /data/paloma/data/paintings/wikiart/vincent-van-gogh_the-starry-night-1889.jpg\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 1: Starry Night\n",
    "image_path = '/data/paloma/data/paintings/wikiart/vincent-van-gogh_the-starry-night-1889.jpg'\n",
    "utterance = \"The swirling sky with vibrant blues and yellows evokes a sense of awe and wonder\"\n",
    "\n",
    "if Path(image_path).exists():\n",
    "    result = predict_emotion(image_path, utterance)\n",
    "    \n",
    "    # Visualizar\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Imagem\n",
    "    axes[0].imshow(result['image'])\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Starry Night - Van Gogh', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Probabilidades\n",
    "    emotions = list(result['probabilities'].keys())\n",
    "    probs = list(result['probabilities'].values())\n",
    "    colors = ['#2ecc71' if e == result['predicted_emotion'] else '#95a5a6' for e in emotions]\n",
    "    \n",
    "    axes[1].barh(emotions, probs, color=colors)\n",
    "    axes[1].set_xlabel('Probability', fontsize=12)\n",
    "    axes[1].set_title(f'Prediction: {result[\"predicted_emotion\"].upper()} ({result[\"confidence\"]:.1%})', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/paloma/cerebrum-artis/outputs/figures/v2_starry_night.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print fuzzy features\n",
    "    print(\"\\nðŸ“Š FUZZY FEATURES:\")\n",
    "    for feat, val in result['fuzzy_features'].items():\n",
    "        print(f\"  {feat:20s}: {val:.3f}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Imagem nÃ£o encontrada: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49516241",
   "metadata": {},
   "source": [
    "### 6.2 Visualizar Features Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5ff681",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(image_path).exists():\n",
    "    # Plot fuzzy features\n",
    "    features = result['fuzzy_features']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    feature_names = list(features.keys())\n",
    "    feature_values = list(features.values())\n",
    "    \n",
    "    bars = ax.barh(feature_names, feature_values, color='#3498db')\n",
    "    \n",
    "    # Highlight high values\n",
    "    for i, (name, val) in enumerate(zip(feature_names, feature_values)):\n",
    "        if val > 0.7:\n",
    "            bars[i].set_color('#e74c3c')  # Red for high\n",
    "        elif val < 0.3:\n",
    "            bars[i].set_color('#95a5a6')  # Gray for low\n",
    "    \n",
    "    ax.set_xlabel('Value [0, 1]', fontsize=12)\n",
    "    ax.set_title('Fuzzy Features - Starry Night', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/paloma/cerebrum-artis/outputs/figures/v2_fuzzy_features_starry.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21948b",
   "metadata": {},
   "source": [
    "## 7. Comparar MÃºltiplas Pinturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2755fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Total processado: 0 imagens\n"
     ]
    }
   ],
   "source": [
    "# Lista de exemplos (ajuste conforme suas imagens disponÃ­veis)\n",
    "examples = [\n",
    "    {\n",
    "        'path': '/data/paloma/data/paintings/wikiart/vincent-van-gogh_the-starry-night-1889.jpg',\n",
    "        'utterance': 'The swirling sky evokes awe and wonder',\n",
    "        'name': 'Starry Night'\n",
    "    },\n",
    "    # Adicione mais exemplos aqui\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for ex in examples:\n",
    "    if Path(ex['path']).exists():\n",
    "        result = predict_emotion(ex['path'], ex['utterance'])\n",
    "        result['name'] = ex['name']\n",
    "        results_list.append(result)\n",
    "        print(f\"âœ… {ex['name']}: {result['predicted_emotion']} ({result['confidence']:.1%})\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Total processado: {len(results_list)} imagens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874cb87",
   "metadata": {},
   "source": [
    "## 8. AnÃ¡lise de ContribuiÃ§Ã£o de Features\n",
    "\n",
    "Visualizar como diferentes features contribuem para a prediÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26005e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_list:\n",
    "    # Create feature matrix\n",
    "    feature_names = ['brightness', 'color_temp', 'saturation', 'harmony', \n",
    "                     'complexity', 'symmetry', 'roughness']\n",
    "    \n",
    "    feature_matrix = []\n",
    "    painting_names = []\n",
    "    \n",
    "    for res in results_list:\n",
    "        features = res['fuzzy_features']\n",
    "        feature_matrix.append([features[f] for f in feature_names])\n",
    "        painting_names.append(res['name'])\n",
    "    \n",
    "    # Heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, len(painting_names)*0.8))\n",
    "    \n",
    "    sns.heatmap(\n",
    "        feature_matrix,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='RdYlBu_r',\n",
    "        xticklabels=feature_names,\n",
    "        yticklabels=painting_names,\n",
    "        cbar_kws={'label': 'Feature Value'},\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Fuzzy Features Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/paloma/cerebrum-artis/outputs/figures/v2_features_heatmap.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30bf476",
   "metadata": {},
   "source": [
    "## 9. Arquitetura do Modelo (Diagrama)\n",
    "\n",
    "Visualizar a arquitetura V2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be104324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚                    V2 - SIMPLE CONCATENATION                â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚                                                             â”‚\n",
      "â”‚  INPUT: Image + Utterance                                   â”‚\n",
      "â”‚                                                             â”‚\n",
      "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
      "â”‚  â”‚   ResNet50   â”‚  â”‚   RoBERTa    â”‚  â”‚    Fuzzy     â”‚     â”‚\n",
      "â”‚  â”‚   (FROZEN)   â”‚  â”‚   (FROZEN)   â”‚  â”‚  Extractor   â”‚     â”‚\n",
      "â”‚  â”‚   23M params â”‚  â”‚  125M params â”‚  â”‚  (7 features)â”‚     â”‚\n",
      "â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
      "â”‚         â”‚                 â”‚                 â”‚              â”‚\n",
      "â”‚         â†“                 â†“                 â†“              â”‚\n",
      "â”‚    [B, 2048]         [B, 768]           [B, 7]            â”‚\n",
      "â”‚         â”‚                 â”‚                 â”‚              â”‚\n",
      "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\n",
      "â”‚                           â”‚                                â”‚\n",
      "â”‚                    [B, 2823]                               â”‚\n",
      "â”‚                           â”‚                                â”‚\n",
      "â”‚                           â†“                                â”‚\n",
      "â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
      "â”‚              â”‚    MLP Fusion          â”‚                    â”‚\n",
      "â”‚              â”‚    (TRAINABLE)         â”‚                    â”‚\n",
      "â”‚              â”‚    ~3M params          â”‚                    â”‚\n",
      "â”‚              â”‚                        â”‚                    â”‚\n",
      "â”‚              â”‚  2823 â†’ 1024 â†’ 512 â†’ 9â”‚                    â”‚\n",
      "â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚\n",
      "â”‚                           â”‚                                â”‚\n",
      "â”‚                           â†“                                â”‚\n",
      "â”‚                    [B, 9 emotions]                         â”‚\n",
      "â”‚                                                             â”‚\n",
      "â”‚  PERFORMANCE: 70.63% accuracy                              â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "\n",
      "âœ… Arquitetura salva em outputs/v2_architecture.txt\n"
     ]
    }
   ],
   "source": [
    "# Criar diagrama de arquitetura textual\n",
    "architecture_text = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    V2 - SIMPLE CONCATENATION                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  INPUT: Image + Utterance                                   â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
    "â”‚  â”‚   ResNet50   â”‚  â”‚   RoBERTa    â”‚  â”‚    Fuzzy     â”‚     â”‚\n",
    "â”‚  â”‚   (FROZEN)   â”‚  â”‚   (FROZEN)   â”‚  â”‚  Extractor   â”‚     â”‚\n",
    "â”‚  â”‚   23M params â”‚  â”‚  125M params â”‚  â”‚  (7 features)â”‚     â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
    "â”‚         â”‚                 â”‚                 â”‚              â”‚\n",
    "â”‚         â†“                 â†“                 â†“              â”‚\n",
    "â”‚    [B, 2048]         [B, 768]           [B, 7]            â”‚\n",
    "â”‚         â”‚                 â”‚                 â”‚              â”‚\n",
    "â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\n",
    "â”‚                           â”‚                                â”‚\n",
    "â”‚                    [B, 2823]                               â”‚\n",
    "â”‚                           â”‚                                â”‚\n",
    "â”‚                           â†“                                â”‚\n",
    "â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
    "â”‚              â”‚    MLP Fusion          â”‚                    â”‚\n",
    "â”‚              â”‚    (TRAINABLE)         â”‚                    â”‚\n",
    "â”‚              â”‚    ~3M params          â”‚                    â”‚\n",
    "â”‚              â”‚                        â”‚                    â”‚\n",
    "â”‚              â”‚  2823 â†’ 1024 â†’ 512 â†’ 9â”‚                    â”‚\n",
    "â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚\n",
    "â”‚                           â”‚                                â”‚\n",
    "â”‚                           â†“                                â”‚\n",
    "â”‚                    [B, 9 emotions]                         â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  PERFORMANCE: 70.63% accuracy                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "\n",
    "print(architecture_text)\n",
    "\n",
    "# Save as text file\n",
    "with open('/home/paloma/cerebrum-artis/outputs/v2_architecture.txt', 'w') as f:\n",
    "    f.write(architecture_text)\n",
    "\n",
    "print(\"\\nâœ… Arquitetura salva em outputs/v2_architecture.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d96ff0",
   "metadata": {},
   "source": [
    "## 10. Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4f616b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "V2 MODEL SUMMARY\n",
      "============================================================\n",
      "Model                    : V2 - Simple Concatenation\n",
      "Architecture             : ResNet50 (frozen) + RoBERTa (frozen) + 7 Fuzzy\n",
      "Total Parameters         : 151,574,857\n",
      "Trainable Parameters     : 3,421,193\n",
      "Frozen Parameters        : 148,153,664\n",
      "Val Accuracy             : 70.63%\n",
      "Training Strategy        : Transfer Learning (frozen encoders)\n",
      "Fusion Method            : Simple Concatenation\n",
      "Key Features             : â€¢ Interpretable fuzzy features\n",
      "â€¢ Fast training (~hours)\n",
      "â€¢ Low computational cost\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create performance summary\n",
    "summary = {\n",
    "    'Model': 'V2 - Simple Concatenation',\n",
    "    'Architecture': 'ResNet50 (frozen) + RoBERTa (frozen) + 7 Fuzzy',\n",
    "    'Total Parameters': f'{total_params:,}',\n",
    "    'Trainable Parameters': f'{trainable_params:,}',\n",
    "    'Frozen Parameters': f'{total_params - trainable_params:,}',\n",
    "    'Val Accuracy': '70.63%',\n",
    "    'Training Strategy': 'Transfer Learning (frozen encoders)',\n",
    "    'Fusion Method': 'Simple Concatenation',\n",
    "    'Key Features': 'â€¢ Interpretable fuzzy features\\nâ€¢ Fast training (~hours)\\nâ€¢ Low computational cost'\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"V2 MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key:25s}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ef90c",
   "metadata": {},
   "source": [
    "## 11. Export para ApresentaÃ§Ã£o\n",
    "\n",
    "Todas as figuras foram salvas em:\n",
    "- `outputs/figures/v2_starry_night.png`\n",
    "- `outputs/figures/v2_fuzzy_features_starry.png`\n",
    "- `outputs/figures/v2_features_heatmap.png`\n",
    "- `outputs/v2_architecture.txt`\n",
    "\n",
    "Use essas imagens na sua apresentaÃ§Ã£o! ðŸŽ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cerebrum-artis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
