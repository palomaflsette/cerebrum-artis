{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import RobertaTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, '/home/paloma/cerebrum-artis')\n",
    "\n",
    "from cerebrum_artis.models.ensemble.ensemble_v4 import EnsembleV4\n",
    "from cerebrum_artis.fuzzy.system import FuzzyEmotionSystem\n",
    "\n",
    "print(\"‚úÖ Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f529a",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o e Carregamento dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "\n",
    "# Checkpoints\n",
    "v2_checkpoint = \"/data/paloma/deep-mind-checkpoints/v2_fuzzy_features/checkpoint_best.pt\"\n",
    "v3_checkpoint = \"/data/paloma/deep-mind-checkpoints/v3_adaptive_gating/checkpoint_best.pt\"\n",
    "\n",
    "# Load ensemble\n",
    "print(\"\\nüì¶ Loading V4 Ensemble...\")\n",
    "ensemble = EnsembleV4(\n",
    "    v2_checkpoint_path=v2_checkpoint,\n",
    "    v3_checkpoint_path=v3_checkpoint,\n",
    "    v2_weight=0.5,\n",
    "    device=device\n",
    ")\n",
    "ensemble.eval()\n",
    "\n",
    "print(\"‚úÖ Ensemble loaded successfully\")\n",
    "print(f\"   V2 weight: 50% | V3 weight: 50%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e90d7",
   "metadata": {},
   "source": [
    "## 2. Prepara√ß√£o de Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dcf28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Fuzzy system\n",
    "fuzzy_system = FuzzyEmotionSystem()\n",
    "\n",
    "# Emotion labels\n",
    "EMOTIONS = [\n",
    "    'amusement', 'awe', 'contentment', 'excitement',\n",
    "    'anger', 'disgust', 'fear', 'sadness', 'something else'\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Transforms and tokenizer ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995af71",
   "metadata": {},
   "source": [
    "## 3. Input: Imagem e Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728fe227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üé® EDITE AQUI: Coloque sua imagem e caption\n",
    "# ========================================\n",
    "\n",
    "# Exemplo: Picasso - The Pigeon Pea (1912)\n",
    "image_path = \"/home/paloma/cerebrum-artis/garbage/test_images/pablo-picasso_the-pigeon-pea-1912.jpg\"\n",
    "caption = \"Fragmented geometric forms with muted earth tones showing analytical cubist style\"\n",
    "\n",
    "# Load and display image\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(f\"INPUT: {os.path.basename(image_path)}\\nCaption: '{caption}'\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üì∏ Image: {os.path.basename(image_path)}\")\n",
    "print(f\"üí¨ Caption: {caption}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fefef3",
   "metadata": {},
   "source": [
    "## 4. Extra√ß√£o de Fuzzy Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22513db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fuzzy features from image\n",
    "fuzzy_features = fuzzy_system.extract_features_from_image(np.array(image))\n",
    "fuzzy_tensor = torch.tensor(fuzzy_features, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "# Display fuzzy features\n",
    "feature_names = ['texture_roughness', 'symmetry', 'complexity', 'color_harmony', \n",
    "                 'saturation', 'color_temperature', 'brightness']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "colors = ['cyan' if f < 0.5 else 'salmon' for f in fuzzy_features]\n",
    "bars = ax.barh(feature_names, fuzzy_features, color=colors, edgecolor='black')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_xlabel('Feature Value', fontsize=12)\n",
    "ax.set_title('FUZZY FEATURES EXTRACTED', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, val) in enumerate(zip(bars, fuzzy_features)):\n",
    "    ax.text(val + 0.02, i, f'{val:.3f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Fuzzy Features:\")\n",
    "for name, val in zip(feature_names, fuzzy_features):\n",
    "    print(f\"   {name}: {val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e3369",
   "metadata": {},
   "source": [
    "## 5. Tokeniza√ß√£o do Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ceaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize caption\n",
    "encoded = tokenizer(\n",
    "    caption,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encoded['input_ids'].to(device)\n",
    "attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "print(f\"‚úÖ Text tokenized: {input_ids.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364b918",
   "metadata": {},
   "source": [
    "## 6. Infer√™ncia: V2, V3 e V4 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ensemble inference\n",
    "with torch.no_grad():\n",
    "    ensemble_logits, v2_logits, v3_logits = ensemble(\n",
    "        image_tensor, input_ids, attention_mask, fuzzy_tensor\n",
    "    )\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    v2_probs = F.softmax(v2_logits, dim=1).cpu().numpy()[0]\n",
    "    v3_probs = F.softmax(v3_logits, dim=1).cpu().numpy()[0]\n",
    "    ensemble_probs = F.softmax(ensemble_logits, dim=1).cpu().numpy()[0]\n",
    "    \n",
    "    # Get predictions\n",
    "    v2_pred = EMOTIONS[v2_probs.argmax()]\n",
    "    v3_pred = EMOTIONS[v3_probs.argmax()]\n",
    "    ensemble_pred = EMOTIONS[ensemble_probs.argmax()]\n",
    "    \n",
    "    # Get top-3 confidences\n",
    "    v2_top3_idx = v2_probs.argsort()[-3:][::-1]\n",
    "    v3_top3_idx = v3_probs.argsort()[-3:][::-1]\n",
    "    ensemble_top3_idx = ensemble_probs.argsort()[-3:][::-1]\n",
    "\n",
    "print(\"\\nüîÆ PREDICTIONS:\")\n",
    "print(f\"   V2 (Fuzzy Features):  {v2_pred} ({v2_probs.max()*100:.1f}%)\")\n",
    "print(f\"   V3 (Adaptive Gating): {v3_pred} ({v3_probs.max()*100:.1f}%)\")\n",
    "print(f\"   V4 (Ensemble):        {ensemble_pred} ({ensemble_probs.max()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüèÜ V2 Top-3 Emotions:\")\n",
    "for idx in v2_top3_idx:\n",
    "    print(f\"   ‚Ä¢ {EMOTIONS[idx]}: {v2_probs[idx]*100:.1f}%\")\n",
    "\n",
    "print(\"\\nüèÜ V3 Top-3 Emotions:\")\n",
    "for idx in v3_top3_idx:\n",
    "    print(f\"   ‚Ä¢ {EMOTIONS[idx]}: {v3_probs[idx]*100:.1f}%\")\n",
    "\n",
    "print(\"\\nüèÜ V4 Ensemble Top-3 Emotions:\")\n",
    "for idx in ensemble_top3_idx:\n",
    "    print(f\"   ‚Ä¢ {EMOTIONS[idx]}: {ensemble_probs[idx]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ac43d",
   "metadata": {},
   "source": [
    "## 7. An√°lise de Agreement (Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between V2 and V3 predictions\n",
    "v2_norm = v2_probs / (np.linalg.norm(v2_probs) + 1e-8)\n",
    "v3_norm = v3_probs / (np.linalg.norm(v3_probs) + 1e-8)\n",
    "agreement = np.dot(v2_norm, v3_norm)\n",
    "\n",
    "print(f\"\\nüîç Agreement Analysis: Cosine Similarity = {agreement:.3f}\")\n",
    "print(f\"   Interpretation:\")\n",
    "if agreement > 0.8:\n",
    "    print(f\"   ‚úÖ HIGH agreement - Models strongly agree\")\n",
    "elif agreement > 0.6:\n",
    "    print(f\"   ‚úì MODERATE agreement - Models somewhat agree\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  LOW agreement - Models disagree\")\n",
    "\n",
    "# Calculate adaptive gating weight (como no V3)\n",
    "max_alpha = 0.8\n",
    "min_alpha = 0.2\n",
    "alpha = max_alpha - (max_alpha - min_alpha) * agreement\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è  Adaptive Gating Metrics (V3 internal):\")\n",
    "print(f\"   Agreement (cosine sim): {agreement:.3f}\")\n",
    "print(f\"   Adaptive Alpha (Œ±): {alpha:.3f}\")\n",
    "print(f\"   Weights:\")\n",
    "print(f\"   ‚Ä¢ Neural: {alpha*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Fuzzy:  {(1-alpha)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3081c",
   "metadata": {},
   "source": [
    "## 8. Visualiza√ß√£o: Compara√ß√£o de Predi√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# V2 predictions\n",
    "axes[0].barh(EMOTIONS, v2_probs, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].set_xlabel('Probability', fontsize=12)\n",
    "axes[0].set_title(f'Neural Network\\n‚Üí {v2_pred} ({v2_probs.max()*100:.1f}%)', \n",
    "                  fontsize=14, fontweight='bold', color='steelblue')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# V3 predictions\n",
    "axes[1].barh(EMOTIONS, v3_probs, color='darkorange', edgecolor='black')\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].set_xlabel('Probability', fontsize=12)\n",
    "axes[1].set_title(f'iFeature Values\\n‚Üí {v3_pred} ({v3_probs.max()*100:.1f}%)', \n",
    "                  fontsize=14, fontweight='bold', color='darkorange')\n",
    "axes[1].set_yticklabels([])\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# V4 Ensemble predictions\n",
    "axes[2].barh(EMOTIONS, ensemble_probs, color='mediumseagreen', edgecolor='black')\n",
    "axes[2].set_xlim(0, 1)\n",
    "axes[2].set_xlabel('Probability', fontsize=12)\n",
    "axes[2].set_title(f'V3 Final (Œ±={alpha:.2f})\\n‚Üí {ensemble_pred} ({ensemble_probs.max()*100:.1f}%)', \n",
    "                  fontsize=14, fontweight='bold', color='mediumseagreen')\n",
    "axes[2].set_yticklabels([])\n",
    "axes[2].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c637f",
   "metadata": {},
   "source": [
    "## 9. Visualiza√ß√£o Completa (Similar ao Exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9964312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.3)\n",
    "\n",
    "# ===== TOP: Image and Fuzzy Features =====\n",
    "ax_img = fig.add_subplot(gs[0, 0:2])\n",
    "ax_img.imshow(image)\n",
    "ax_img.axis('off')\n",
    "ax_img.set_title(f\"INPUT: {os.path.basename(image_path)}\\nCaption: '{caption}'\", \n",
    "                 fontsize=12, fontweight='bold')\n",
    "\n",
    "ax_fuzzy = fig.add_subplot(gs[0, 2])\n",
    "colors_fuzzy = ['cyan' if f < 0.5 else 'salmon' for f in fuzzy_features]\n",
    "ax_fuzzy.barh(feature_names, fuzzy_features, color=colors_fuzzy, edgecolor='black')\n",
    "ax_fuzzy.set_xlim(0, 1)\n",
    "ax_fuzzy.set_xlabel('Value', fontsize=10)\n",
    "ax_fuzzy.set_title('FUZZY FEATURES EXTRACTED', fontsize=12, fontweight='bold')\n",
    "ax_fuzzy.grid(axis='x', alpha=0.3)\n",
    "for i, val in enumerate(fuzzy_features):\n",
    "    ax_fuzzy.text(val + 0.02, i, f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "# ===== MIDDLE: Predictions V2, V3, V4 =====\n",
    "ax_v2 = fig.add_subplot(gs[1, 0])\n",
    "ax_v2.barh(EMOTIONS, v2_probs, color='steelblue', edgecolor='black')\n",
    "ax_v2.set_xlim(0, 1)\n",
    "ax_v2.set_xlabel('Probability', fontsize=10)\n",
    "ax_v2.set_title(f'Neural Network\\n‚Üí {v2_pred} ({v2_probs.max()*100:.1f}%)', \n",
    "                fontsize=12, fontweight='bold', color='steelblue')\n",
    "ax_v2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "ax_v3 = fig.add_subplot(gs[1, 1])\n",
    "ax_v3.barh(EMOTIONS, v3_probs, color='darkorange', edgecolor='black')\n",
    "ax_v3.set_xlim(0, 1)\n",
    "ax_v3.set_xlabel('Probability', fontsize=10)\n",
    "ax_v3.set_title(f'iFeature Values\\n‚Üí {v3_pred} ({v3_probs.max()*100:.1f}%)', \n",
    "                fontsize=12, fontweight='bold', color='darkorange')\n",
    "ax_v3.set_yticklabels([])\n",
    "ax_v3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "ax_v4 = fig.add_subplot(gs[1, 2])\n",
    "ax_v4.barh(EMOTIONS, ensemble_probs, color='mediumseagreen', edgecolor='black')\n",
    "ax_v4.set_xlim(0, 1)\n",
    "ax_v4.set_xlabel('Probability', fontsize=10)\n",
    "ax_v4.set_title(f'V3 Final (Œ±={alpha:.2f})\\n‚Üí {ensemble_pred} ({ensemble_probs.max()*100:.1f}%)', \n",
    "                fontsize=12, fontweight='bold', color='mediumseagreen')\n",
    "ax_v4.set_yticklabels([])\n",
    "ax_v4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# ===== BOTTOM: Agreement Analysis =====\n",
    "ax_agreement = fig.add_subplot(gs[2, :])\n",
    "\n",
    "x = np.arange(len(EMOTIONS))\n",
    "width = 0.25\n",
    "\n",
    "ax_agreement.bar(x - width, v2_probs, width, label='Neural', color='steelblue', edgecolor='black')\n",
    "ax_agreement.bar(x, v3_probs, width, label='Fuzzy', color='darkorange', edgecolor='black')\n",
    "ax_agreement.bar(x + width, ensemble_probs, width, label='V3 Final', color='mediumseagreen', edgecolor='black')\n",
    "\n",
    "ax_agreement.set_ylabel('Probability', fontsize=12)\n",
    "ax_agreement.set_xlabel('Emotions', fontsize=12)\n",
    "ax_agreement.set_title(f'Agreement Analysis: Cosine Similarity = {agreement:.3f}', \n",
    "                       fontsize=14, fontweight='bold')\n",
    "ax_agreement.set_xticks(x)\n",
    "ax_agreement.set_xticklabels(EMOTIONS, rotation=45, ha='right')\n",
    "ax_agreement.legend(loc='upper right', fontsize=11)\n",
    "ax_agreement.grid(axis='y', alpha=0.3)\n",
    "ax_agreement.set_ylim(0, max(v2_probs.max(), v3_probs.max(), ensemble_probs.max()) * 1.1)\n",
    "\n",
    "# Add text box with metrics\n",
    "metrics_text = f\"\"\"ADAPTIVE GATING METRICS\n",
    "\n",
    "Agreement (cosine sim):\n",
    "{agreement:.3f}\n",
    "\n",
    "Adaptive Weight Alpha (Œ±):\n",
    "{alpha:.3f}\n",
    "\n",
    "Weights:\n",
    "‚Ä¢ Neural: {alpha*100:.1f}%\n",
    "‚Ä¢ Fuzzy: {(1-alpha)*100:.1f}%\n",
    "\n",
    "Top 3 Emotions (Final):\n",
    "‚Ä¢ {EMOTIONS[ensemble_top3_idx[0]]}: {ensemble_probs[ensemble_top3_idx[0]]*100:.1f}%\n",
    "‚Ä¢ {EMOTIONS[ensemble_top3_idx[1]]}: {ensemble_probs[ensemble_top3_idx[1]]*100:.1f}%\n",
    "‚Ä¢ {EMOTIONS[ensemble_top3_idx[2]]}: {ensemble_probs[ensemble_top3_idx[2]]*100:.1f}%\n",
    "\"\"\"\n",
    "\n",
    "ax_agreement.text(1.02, 0.5, metrics_text, transform=ax_agreement.transAxes,\n",
    "                  fontsize=10, verticalalignment='center',\n",
    "                  bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('V4 ENSEMBLE PREDICTION ANALYSIS', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493feec",
   "metadata": {},
   "source": [
    "## 10. Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac5d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìä V4 ENSEMBLE - PREDICTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüé® INPUT:\")\n",
    "print(f\"   Image: {os.path.basename(image_path)}\")\n",
    "print(f\"   Caption: '{caption}'\")\n",
    "\n",
    "print(f\"\\nüîÆ PREDICTIONS:\")\n",
    "print(f\"   V2 (Concatenation):   {v2_pred:20s} confidence={v2_probs.max()*100:5.1f}%\")\n",
    "print(f\"   V3 (Adaptive Gating): {v3_pred:20s} confidence={v3_probs.max()*100:5.1f}%\")\n",
    "print(f\"   V4 (Ensemble):        {ensemble_pred:20s} confidence={ensemble_probs.max()*100:5.1f}%\")\n",
    "\n",
    "print(f\"\\nüîç AGREEMENT:\")\n",
    "print(f\"   Cosine Similarity: {agreement:.3f}\")\n",
    "print(f\"   Status: {'‚úÖ HIGH' if agreement > 0.8 else '‚úì MODERATE' if agreement > 0.6 else '‚ö†Ô∏è LOW'}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è  ENSEMBLE WEIGHTS:\")\n",
    "print(f\"   V2: 50.0%\")\n",
    "print(f\"   V3: 50.0%\")\n",
    "\n",
    "print(f\"\\nüèÜ FINAL PREDICTION: {ensemble_pred.upper()}\")\n",
    "print(f\"   Confidence: {ensemble_probs.max()*100:.1f}%\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
