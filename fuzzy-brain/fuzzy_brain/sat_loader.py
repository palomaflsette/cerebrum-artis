"""
SAT Model Loader - Carrega modelo M2 Transformer treinado
"""
import torch
import pickle
import sys
from pathlib import Path

# Adiciona paths necess√°rios
artemis_path = Path(__file__).parent.parent.parent / 'artemis' / 'neural_speaker' / 'm2'
sys.path.insert(0, str(artemis_path))

from models.transformer import (
    MemoryAugmentedEncoder, 
    MeshedDecoder,
    ScaledDotProductAttentionMemory, 
    Transformer
)


class SATModelLoader:
    """
    Carrega o modelo SAT (M2 Transformer) treinado no ArtEmis.
    
    Attributes:
        model: Transformer model (encoder + decoder)
        vocab: Vocabul√°rio de palavras
        emotion_encoder: Encoder de emo√ß√µes (se usado)
        device: 'cuda' ou 'cpu'
    """
    
    def __init__(
        self,
        checkpoint_path: str,
        vocab_path: str,
        use_emotion_labels: bool = True,
        device: str = 'cpu'
    ):
        """
        Inicializa e carrega o modelo SAT.
        
        Args:
            checkpoint_path: Caminho para checkpoint (.pt)
            vocab_path: Caminho para vocabul√°rio (.pkl)
            use_emotion_labels: Se True, carrega emotion encoder
            device: 'cuda' ou 'cpu'
        """
        self.device = device
        self.use_emotion_labels = use_emotion_labels
        
        # 1. Carrega vocabul√°rio
        print(f"üìö Carregando vocabul√°rio de {vocab_path}...")
        with open(vocab_path, 'rb') as f:
            self.vocab = pickle.load(f)
        
        vocab_size = len(self.vocab)
        pad_idx = self.vocab.pad
        bos_idx = self.vocab.sos  # SOS = Start Of Sequence = BOS
        
        print(f"  ‚úÖ Vocabul√°rio: {vocab_size} tokens")
        
        # 2. Constr√≥i modelo (mesma arquitetura do treinamento)
        print("üß† Construindo modelo M2 Transformer...")
        
        emotion_dim = 0
        self.emotion_encoder = None
        
        if use_emotion_labels:
            emotion_dim = 10
            self.emotion_encoder = torch.nn.Sequential(
                torch.nn.Linear(9, emotion_dim)
            )
        
        # Encoder: MemoryAugmentedEncoder (M=40 memory slots)
        encoder = MemoryAugmentedEncoder(
            N=3,  # 3 layers
            padding_idx=0,
            attention_module=ScaledDotProductAttentionMemory,
            attention_module_kwargs={'m': 40},  # 40 memory slots
            d_in=2048 + emotion_dim  # ResNet50 features + emotion
        )
        
        # Decoder: MeshedDecoder
        decoder = MeshedDecoder(
            vocab_size=vocab_size,
            max_len=54,
            N_dec=3,  # 3 decoder layers
            padding_idx=pad_idx
        )
        
        # Transformer completo
        self.model = Transformer(bos_idx, encoder, decoder)
        
        # 3. Carrega pesos do checkpoint
        print(f"‚öôÔ∏è  Carregando checkpoint de {checkpoint_path}...")
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # Carrega state_dict
        self.model.load_state_dict(checkpoint['model'])
        
        if use_emotion_labels and 'emotion_encoder' in checkpoint:
            self.emotion_encoder.load_state_dict(checkpoint['emotion_encoder'])
        
        # Move para device
        self.model.to(device)
        if self.emotion_encoder is not None:
            self.emotion_encoder.to(device)
        
        self.model.eval()
        if self.emotion_encoder is not None:
            self.emotion_encoder.eval()
        
        print(f"  ‚úÖ Modelo carregado! (epoch {checkpoint.get('epoch', '?')})")
        print(f"  üìä Best CIDEr: {checkpoint.get('best_cider', 'N/A')}")
    
    @torch.no_grad()
    def extract_emotion_logits(self, image_features, emotion_label):
        """
        Extrai logits de emo√ß√µes usando o decoder.
        
        NOTA: O modelo M2 √© um CAPTIONING model, n√£o classificador.
        Para obter probabilidades de emo√ß√µes, precisamos de outra abordagem.
        
        Args:
            image_features: Features visuais (B, num_regions, 2048)
            emotion_label: One-hot emotion (B, 9)
        
        Returns:
            Logits sobre vocabul√°rio (n√£o sobre emo√ß√µes)
        """
        raise NotImplementedError(
            "O modelo M2 √© um IMAGE CAPTIONING model, n√£o classificador de emo√ß√µes!\n"
            "Ele gera TEXTO descrevendo emo√ß√µes, n√£o prediz probabilidades.\n\n"
            "Para classifica√ß√£o de emo√ß√µes, voc√™ precisa:\n"
            "1. Usar apenas o ENCODER + um classificador linear no topo, OU\n"
            "2. Treinar um modelo separado para classifica√ß√£o (ResNet50 + FC)"
        )
    
    def __repr__(self):
        return (
            f"SATModelLoader(\n"
            f"  vocab_size={len(self.vocab)},\n"
            f"  emotion_encoder={'Yes' if self.emotion_encoder else 'No'},\n"
            f"  device={self.device}\n"
            f")"
        )


# ============================================================================
# TESTE R√ÅPIDO
# ============================================================================

if __name__ == "__main__":
    import os
    
    # Paths
    artemis_root = Path(__file__).parent.parent.parent / 'artemis'
    checkpoint_path = artemis_root / 'sat_logs' / 'sat_combined' / 'checkpoints' / 'best_model.pt'
    vocab_path = artemis_root / 'dataset' / 'combined' / 'train' / 'vocabulary.pkl'
    
    print("="*70)
    print("TESTE: Carregamento do modelo SAT")
    print("="*70)
    
    if not checkpoint_path.exists():
        print(f"‚ùå Checkpoint n√£o encontrado: {checkpoint_path}")
        exit(1)
    
    if not vocab_path.exists():
        print(f"‚ùå Vocabul√°rio n√£o encontrado: {vocab_path}")
        exit(1)
    
    # Carrega modelo
    loader = SATModelLoader(
        checkpoint_path=str(checkpoint_path),
        vocab_path=str(vocab_path),
        use_emotion_labels=True,
        device='cpu'
    )
    
    print("\n" + "="*70)
    print(loader)
    print("="*70)
    print("\n‚úÖ Modelo SAT carregado com sucesso!")
    print("\nNOTA: Este √© um modelo de CAPTIONING, n√£o classifica√ß√£o.")
    print("Para classifica√ß√£o de emo√ß√µes, precisaremos de abordagem diferente.")
    print("="*70 + "\n")
